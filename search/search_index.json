{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> The fast, most optimal, and correct HTML &amp; XML parsing library </p> <p>DOCUMENTATION: https://awolverp.github.io/markupever</p> <p>SOURCE CODE: https://github.com/awolverp/markupever</p> <p>MarkupEver is a modern, fast (high-performance), XML &amp; HTML languages parsing library written in Rust.</p> <ul> <li> <p> - Fast</p> <p>Very high performance and fast (thanks to html5ever and selectors).</p> <p>Benchmarks </p> </li> <li> <p> - Easy To Use</p> <p>Designed to be easy to use and learn. Completion everywhere.</p> <p>Examples </p> </li> <li> <p> - Low Memory Usage</p> <p>Written in Rust. Uses low memory. Don't worry about memory leaks. Uses Rust memory allocator.</p> <p>Memory Usage </p> </li> <li> <p> - Your CSS Knowledge</p> <p>Use your CSS knowledge for selecting elements from a HTML or XML document.</p> <p>Querying </p> </li> </ul> <p>Support</p> <p>I ask for your support to continue on this path and make this Python library better and better (1)</p> <ol> <li>Star github repository and tell me in issues your ideas and questions</li> </ol>"},{"location":"#examples","title":"Examples","text":""},{"location":"#parsing-scraping","title":"Parsing &amp; Scraping","text":"<p>Parsing a HTML content and selecting elements:</p> <p>Imagine this <code>index.html</code> file:</p> index.html<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;Example Document&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1 id=\"title\"&gt;Welcome to My Page&lt;/h1&gt;\n    &lt;p&gt;This page has a link and an image.&lt;/p&gt;\n    &lt;a href=\"https://www.example.com\"&gt;Visit Example.com&lt;/a&gt;\n    &lt;br&gt;\n    &lt;img src=\"https://www.example.com/image.jpg\" alt=\"My Image\"&gt;\n    &lt;a href=\"https://www.google.com\"&gt;Visit Google&lt;/a&gt;\n    &lt;a&gt;No Link&lt;/a&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>We want to extract <code>href</code> attributes from this file - We have 3 ways:</p> Parse ContentRead From FileUse Parser Directly <p>You can parse HTML/XML content with <code>parse()</code> function.</p> main.py<pre><code>import markupever\nwith open(\"index.html\", \"rb\") as fd: # (2)!\n    dom = markupever.parse(fd.read(), markupever.HtmlOptions()) # (1)!\n\nfor element in dom.select(\"a[href]\"):\n    print(element.attrs[\"href\"])\n</code></pre> <ol> <li> <p>Use <code>HtmlOptions()</code> for HTML documents and <code>XmlOptions()</code> for XML documents. If you used it incorrectly, don't worry; it won't disrupt the process. These options specify namespaces and such differences between XML and HTML. Additionally, each provides you with different features.</p> </li> <li> <p>It's recommended to open files with <code>\"rb\"</code> mode, but not required; you can use <code>\"r\"</code> mode also.</p> </li> </ol> <p>You can parse HTML/XML content from files with <code>.parse_file()</code> function.</p> main.py<pre><code>import markupever\ndom = markupever.parse_file(\"index.html\", markupever.HtmlOptions()) # (1)!\n\nfor element in dom.select(\"a[href]\"):\n    print(element.attrs[\"href\"])\n</code></pre> <ol> <li>Use <code>HtmlOptions()</code> for HTML documents and <code>XmlOptions()</code> for XML documents. If you used it incorrectly, don't worry; it won't disrupt the process. These options specify namespaces and such differences between XML and HTML. Additionally, each provides you with different features.</li> </ol> <p>These <code>.parse()</code> and <code>.parse_file()</code> function is a shorthand for using <code>.Parser</code> class. But you can use it directly. It's designed to allow you to stream input using <code>.process()</code> method; By this way you are don't worry about memory usages of huge inputs.</p> main.py<pre><code>import markupever\nparser = markupever.Parser(markupever.HtmlOptions()) # (1)!\n\nwith open(\"index.html\", \"rb\") as fd: # (2)!\n    for line in fd: # Read line by line (3)\n        parser.process(line)\n\nparser.finish()\ndom = parser.into_dom()\n\nfor element in dom.select(\"a[href]\"):\n    print(element.attrs[\"href\"])\n</code></pre> <ol> <li> <p>Use <code>HtmlOptions()</code> for HTML documents and <code>XmlOptions()</code> for XML documents. If you used it incorrectly, don't worry; it won't disrupt the process. These options specify namespaces and such differences between XML and HTML. Additionally, each provides you with different features.</p> </li> <li> <p>It's recommended to open files with <code>\"rb\"</code> mode, but not required; you can use <code>\"r\"</code> mode also.</p> </li> <li> <p>You can read the file all at once and pass it to the <code>process</code> function. We have broken the file into lines here to show you the <code>Parser</code>'s abilities.</p> </li> </ol> <p>Then run <code>main.py</code> to see result:</p> <pre><code>$ python3 main.py\nhttps://www.example.com\nhttps://www.google.com\n</code></pre>"},{"location":"#creating-documents","title":"Creating Documents","text":"<p>Also there's a structure called <code>TreeDom</code> (1). You can directly work with it and generate documents (such as HTML and XML) very easy.</p> <ol> <li>A tree structure which specialy designed for HTML and XML documents. Uses Rust's <code>Vec</code> type in backend.     The memory consumed by the <code>TreeDom</code> is dynamic and depends on the number of tokens stored in the tree.     The allocated memory is never reduced and is only released when it is dropped.</li> </ol> <pre><code>from markupever import dom\n\ndom = dom.TreeDom()\nroot: dom.Document = dom.root()\n\nroot.create_doctype(\"html\")\n\nhtml = root.create_element(\"html\", {\"lang\": \"en\"})\nbody = html.create_element(\"body\")\nbody.create_text(\"Hello Everyone ...\")\n\nprint(root.serialize())\n# &lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;body&gt;Hello Everyone ...&lt;/body&gt;&lt;/html&gt;\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<p>You can install MarkupEver by using pip:</p> <pre><code>$ pip3 install markupever\n</code></pre> <p>Use Virtual Environments</p> <p>It is recommended to use virtual environments for installing and using libraries in Python.</p> Linux (venv)Linux (virtualenv)Windows (venv)Windows (virtualenv) <pre><code>$ python3 -m venv venv\n$ source venv/bin/activate\n</code></pre> <pre><code>$ virtualenv venv\n$ source venv/bin/activate\n</code></pre> <pre><code>$ python3 -m venv venv\n$ venv\\Scripts\\activate\n</code></pre> <pre><code>$ virtualenv venv\n$ venv\\Scripts\\activate\n</code></pre>"},{"location":"#performance","title":"Performance","text":"<p>This library is designed by focusing on performance and speed. It's written in Rust and avoids unsafe code blocks.</p> <p>I compared MarkupEver with BeautifulSoup and Parsel (which is directly using lxml):</p>"},{"location":"#benchmarks","title":"Benchmarks","text":"<p>System</p> <p>The system on which the benchmarks are done: Manjaro Linux x86_64, 8G, Intel i3-1115G4</p> Parsing Min Max Avg markupever 4907\u00b5s 4966\u00b5s 4927\u00b5s markupever (exact_errors) 8920\u00b5s 9172\u00b5s 8971\u00b5s beautifulsoup4 (html.parser) 35283\u00b5s 36460\u00b5s 35828\u00b5s beautifulsoup4 (lxml) 22576\u00b5s 23092\u00b5s 22809\u00b5s parsel 3937\u00b5s 4147\u00b5s 4072\u00b5s Selecting (CSS) Min Max Avg markupever 308\u00b5s 314\u00b5s 310\u00b5s beautifulsoup4 2936\u00b5s 3074\u00b5s 2995\u00b5s parsel 159\u00b5s 165\u00b5s 161\u00b5s Serializing Min Max Avg markupever 1932\u00b5s 1973\u00b5s 1952\u00b5s beautifulsoup4 14705\u00b5s 15021\u00b5s 14900\u00b5s parsel 1264\u00b5s 1290\u00b5s 1276\u00b5s <p>Summary</p> <p>The Parsel is the fastest library (Actually <code>lxml</code> is) and is specially designed for scraping, but it offers less control over the document. The BeautifulSoup is the slowest (and oldest) library which provides full control over the document.</p> <p>The MarkupEver sites between these two. It is extremely fast, close to Parsel, and offers full control over the document.</p>"},{"location":"#memory-usage","title":"Memory Usage","text":"<p>As you know this library is written by Rust, and uses Rust allocator; Like other libraries which are written in C and other low-level languages, It uses very low memory and you don't have to worry about memory usage. Manage big documents without worry ...</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the MPL-2.0 license.</p>"},{"location":"parser/","title":"Getting started","text":"<p>The first thing expected from such this libraries is the ability to read HTML, XML, and similar documents.</p> <p>The MarkupEver is designed specially for reading, parsing, and repairing HTML and XML documents (also can parse similar documents).</p> <p>In MarkupEver we have some functions (1) and a class (2) for doing that.</p> <ol> <li><code>.parse()</code> and <code>.parse_file()</code> functions</li> <li><code>Parser</code> class</li> </ol> <p>Additionaly, they have special features that distinguish this library from others:</p> <ul> <li>You don't worry about huge memory usage.</li> <li>You can read and parse documents part by part (such as files, streams, ...).</li> <li>You can specify some options by parsing which are help you (with <code>HtmlOptions()</code> ans <code>XmlOptions()</code> classes).</li> <li>You can repair invalid documents automatically.</li> </ul>"},{"location":"parser/#parsing-html","title":"Parsing Html","text":"<p>Imagine this <code>index.html</code> file:</p> index.html<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Incomplete Html&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;ul&gt;\n        &lt;li&gt;&lt;a href=\"https://www.example.com\"&gt;Example Website&lt;/a&gt;&lt;/li&gt;\n        &lt;li&gt;&lt;a href=\"https://www.wikipedia.org\"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;\n        &lt;li&gt;&lt;a href=\"https://www.bbc.com\"&gt;BBC&lt;/a&gt;&lt;/li&gt;\n        &lt;li&gt;&lt;a href=\"https://www.microsoft.com\"&gt;Microsoft&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n</code></pre> <p>We can use <code>.parse()</code> and <code>.parse_file()</code> functions to parse documents.</p> <p>The Difference</p> <p>the <code>.parse_file()</code> function gets a <code>BinaryIO</code>, a <code>TextIO</code> or a file path and parses it chunk by chunk; but <code>.parse()</code> function gets all document content at once. By this way, using <code>.parse_file()</code> is very better than <code>.parse()</code>.</p> <p>Let's use them:</p> .parse() function.parse_file() function <pre><code>import markupever\n\nwith open(\"index.html\", \"rb\") as fd:\n    dom = markupever.parse(fd.read(), markupever.HtmlOptions())\n</code></pre> <pre><code>import markupever\n\ndom = markupever.parse_file(\"index.html\", markupever.HtmlOptions())\n</code></pre> <p>HtmlOptions</p> <p>Let's see what options we have ...</p> <ul> <li><code>full_document</code> - Specifies that is this a complete document? default: True.</li> <li><code>exact_errors</code> - Report all parse errors described in the spec, at some performance penalty? default: False.</li> <li><code>discard_bom</code> - Discard a <code>U+FEFF BYTE ORDER MARK</code> if we see one at the beginning of the stream? default: False.</li> <li><code>profile</code> - Keep a record of how long we spent in each state? Printed when <code>finish()</code> is called. default: False.</li> <li><code>iframe_srcdoc</code> - Is this an <code>iframe srcdoc</code> document? default: False.</li> <li><code>drop_doctype</code> - Should we drop the DOCTYPE (if any) from the tree? default: False.</li> <li><code>quirks_mode</code> - Initial TreeBuilder quirks mode. default: <code>markupever.QUIRKS_MODE_OFF</code>.</li> </ul> <p>That's it, we parsed <code>index.html</code> file and now have a <code>TreeDom</code> class. We can navigate that:</p> <pre><code>root = dom.root() # Get root node\nroot\n# Document\n\ntitle = root.select_one(\"title\") # Accepts CSS selectors\ntitle.name\n# QualName(local=\"title\", ns=\"http://www.w3.org/1999/xhtml\", prefix=None)\n\ntitle.serialize()\n# '&lt;title&gt;Incomplete Html&lt;/title&gt;'\n\ntitle.text()\n# 'Incomplete Html'\n\ntitle.parent.name\n# QualName(local=\"head\", ns=\"http://www.w3.org/1999/xhtml\", prefix=None)\n\nul = root.select_one(\"ul\")\nul.serialize()\n# &lt;ul&gt;\n#     &lt;li&gt;&lt;a href=\"https://www.example.com\"&gt;Example Website&lt;/a&gt;&lt;/li&gt;\n#     &lt;li&gt;&lt;a href=\"https://www.wikipedia.org\"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;\n#     &lt;li&gt;&lt;a href=\"https://www.bbc.com\"&gt;BBC&lt;/a&gt;&lt;/li&gt;\n#     &lt;li&gt;&lt;a href=\"https://www.microsoft.com\"&gt;Microsoft&lt;/a&gt;&lt;/li&gt;\n# &lt;/ul&gt;\n</code></pre> <p>Common task</p> <p>One common tasks is extracting all links from a page: <pre><code>for tag in root.select(\"a[href^='https://']\"):\n    print(tag.attrs[\"href\"])\n\n# https://www.example.com\n# https://www.wikipedia.org\n# https://www.bbc.com\n# https://www.microsoft.com\n</code></pre></p> <p>Additionaly, if you serialize the parsed DOM you'll see that the incomplete HTML is repaired: <pre><code>root.serialize()\n# &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;\n#     &lt;title&gt;Incomplete Html&lt;/title&gt;\n# &lt;/head&gt;\n# &lt;body&gt;\n#     &lt;ul&gt;\n#         &lt;li&gt;&lt;a href=\"https://www.example.com\"&gt;Example Website&lt;/a&gt;&lt;/li&gt;\n#         &lt;li&gt;&lt;a href=\"https://www.wikipedia.org\"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;\n#         &lt;li&gt;&lt;a href=\"https://www.bbc.com\"&gt;BBC&lt;/a&gt;&lt;/li&gt;\n#         &lt;li&gt;&lt;a href=\"https://www.microsoft.com\"&gt;Microsoft&lt;/a&gt;&lt;/li&gt;\n#     &lt;/ul&gt;\n# &lt;/body&gt;&lt;/html&gt;\n</code></pre></p>"},{"location":"parser/#parsing-xml","title":"Parsing XML","text":"<p>Imagine this <code>file.xml</code> file:</p> file.xml<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;bookstore xmlns:bk=\"http://www.example.com/books\" xmlns:mag=\"http://www.example.com/magazines\"&gt;\n  &lt;bk:book&gt;\n    &lt;bk:title&gt;Programming for Beginners&lt;/bk:title&gt;\n    &lt;bk:author&gt;Jane Doe&lt;/bk:author&gt;\n    &lt;bk:year&gt;2021&lt;/bk:year&gt;\n  &lt;/bk:book&gt;\n  &lt;mag:magazine&gt;\n    &lt;mag:title&gt;Technology Monthly&lt;/mag:title&gt;\n    &lt;mag:publisher&gt;Tech Publishers&lt;/mag:publisher&gt;\n    &lt;mag:month&gt;March&lt;/mag:month&gt;\n  &lt;/mag:magazine&gt;\n&lt;/bookstore&gt;\n</code></pre> <p>Let's use <code>.parse()</code> / <code>.parse_file()</code> function to parse it (we explained them earlier):</p> .parse() function.parse_file() function <pre><code>import markupever\n\nwith open(\"file.xml\", \"rb\") as fd:\n    dom = markupever.parse(fd.read(), markupever.XmlOptions())\n</code></pre> <pre><code>import markupever\n\ndom = markupever.parse_file(\"file.xml\", markupever.XmlOptions())\n</code></pre> <p>XmlOptions</p> <p>Let's see what options we have ...</p> <ul> <li><code>exact_errors</code> - Report all parse errors described in the spec, at some performance penalty? default: False.</li> <li><code>discard_bom</code> - Discard a <code>U+FEFF BYTE ORDER MARK</code> if we see one at the beginning of the stream? default: False.</li> <li><code>profile</code> - Keep a record of how long we spent in each state? Printed when <code>finish()</code> is called. default: False.</li> </ul> <p>That's it, we parsed <code>file.xml</code> file and now have a <code>TreeDom</code> class. We can navigate that like what we did in this section:</p> <pre><code>root = dom.root() # Get root node\nroot\n# Document\n\nroot.select_one(\"bookstore\")\n# Element(name=QualName(local=\"bookstore\", ns=\"\", prefix=None), attrs=[], template=false, mathml_annotation_xml_integration_point=false)\n\nfor i in root.select(\"mag|*\"): # get all elements which has namespace 'mag'\n    print(i)\n# Element(name=QualName(local=\"magazine\", ns=\"http://www.example.com/magazines\", prefix=Some(\"mag\")), attrs=[], template=false, mathml_annotation_xml_integration_point=false)\n# Element(name=QualName(local=\"title\", ns=\"http://www.example.com/magazines\", prefix=Some(\"mag\")), attrs=[], template=false, mathml_annotation_xml_integration_point=false)\n# Element(name=QualName(local=\"publisher\", ns=\"http://www.example.com/magazines\", prefix=Some(\"mag\")), attrs=[], template=false, mathml_annotation_xml_integration_point=false)\n# Element(name=QualName(local=\"month\", ns=\"http://www.example.com/magazines\", prefix=Some(\"mag\")), attrs=[], template=false, mathml_annotation_xml_integration_point=false)\n\nbook = root.select_one(\"book\")\nbook.serialize()\n# &lt;bk:book xmlns:bk=\"http://www.example.com/books\"&gt;\n#   &lt;bk:title&gt;Programming for Beginners&lt;/bk:title&gt;\n#   &lt;bk:author&gt;Jane Doe&lt;/bk:author&gt;\n#   &lt;bk:year&gt;2021&lt;/bk:year&gt;\n# &lt;/bk:book&gt;\n</code></pre>"},{"location":"parser/#using-parser","title":"Using Parser","text":"<p>Comming Soon ...</p>"},{"location":"parser/#more-about-options","title":"More about options","text":"<p>Comming Soon ...</p>"},{"location":"querying/","title":"Querying","text":"<p>Comming Soon ...</p>"},{"location":"reference/","title":"Reference","text":"<p>Comming Soon ...</p>"},{"location":"treedom/","title":"TreeDom","text":"<p>Comming Soon ...</p>"}]}